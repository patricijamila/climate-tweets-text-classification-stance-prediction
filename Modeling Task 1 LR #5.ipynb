{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e70b52-182a-4a77-82dd-e89ed14be0b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6329634-0988-4b8d-9c1b-39c1a8054a55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6329634-0988-4b8d-9c1b-39c1a8054a55",
    "outputId": "99e1cff0-cb77-458c-b613-489d53c031c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import html\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64e99b75-b67c-4e7b-8d20-77ea79022edb",
   "metadata": {
    "id": "64e99b75-b67c-4e7b-8d20-77ea79022edb"
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/training_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14fec360-2649-4e99-a39e-760d17eaf5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>id</th>\n",
       "      <th>lang</th>\n",
       "      <th>place</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>user_location</th>\n",
       "      <th>tweet_proc_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tcot, tlot, climatechange, solar]</td>\n",
       "      <td>0</td>\n",
       "      <td>1010598407596072962</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>icymi learn mandate rooftop solar power cause ...</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nationalhurricanecenter, climatechange, hurri...</td>\n",
       "      <td>1</td>\n",
       "      <td>1035418425047298049</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>nationalhurricanecenter hype storm convince cl...</td>\n",
       "      <td>USA</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[theresistance, altleft, antifa, waronwomen, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>968236700794175488</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>hey theresistance altleft antifa waronwomen fe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nos, eenvandaag, nieuwsuur, groenlinks, jinek...</td>\n",
       "      <td>0</td>\n",
       "      <td>968239413770760194</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>de jaren ge het globaal koeling compilation ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[skybastard, idonotconsent, wedonotconsent, op...</td>\n",
       "      <td>1</td>\n",
       "      <td>1067506402543964161</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>lovely little skybastard idonotconsent wedonot...</td>\n",
       "      <td>Right Here......</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hashtags  favorite_count  \\\n",
       "0                 [tcot, tlot, climatechange, solar]               0   \n",
       "1  [nationalhurricanecenter, climatechange, hurri...               1   \n",
       "2  [theresistance, altleft, antifa, waronwomen, f...               0   \n",
       "3  [nos, eenvandaag, nieuwsuur, groenlinks, jinek...               0   \n",
       "4  [skybastard, idonotconsent, wedonotconsent, op...               1   \n",
       "\n",
       "                    id lang place  retweet_count  \\\n",
       "0  1010598407596072962   en   NaN              0   \n",
       "1  1035418425047298049   en   NaN              0   \n",
       "2   968236700794175488   en   NaN              0   \n",
       "3   968239413770760194   en   NaN              0   \n",
       "4  1067506402543964161   en   NaN              1   \n",
       "\n",
       "                                                text     user_location  \\\n",
       "0  icymi learn mandate rooftop solar power cause ...  Washington, D.C.   \n",
       "1  nationalhurricanecenter hype storm convince cl...               USA   \n",
       "2  hey theresistance altleft antifa waronwomen fe...               NaN   \n",
       "3  de jaren ge het globaal koeling compilation ne...               NaN   \n",
       "4  lovely little skybastard idonotconsent wedonot...  Right Here......   \n",
       "\n",
       "   tweet_proc_length  target  \n",
       "0                 19       0  \n",
       "1                 39       0  \n",
       "2                 24       0  \n",
       "3                 33       0  \n",
       "4                 21       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a350dd-5834-4eab-af80-134568412fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    82735\n",
       "0    74462\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a51aaa-c52a-4a83-9776-5464607b9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['text','target']\n",
    "df = df.loc[:, col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90c38280-9e09-4e7e-9d01-8acf0684a618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>icymi learn mandate rooftop solar power cause ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nationalhurricanecenter hype storm convince cl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey theresistance altleft antifa waronwomen fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de jaren ge het globaal koeling compilation ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lovely little skybastard idonotconsent wedonot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157192</th>\n",
       "      <td>tonight feel like canada strange turn learn ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157193</th>\n",
       "      <td>lead cause climate change thing far animal agr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157194</th>\n",
       "      <td>curious date global air temperature climate ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157195</th>\n",
       "      <td>sign climatechange climateemergencynow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157196</th>\n",
       "      <td>federal judge rule tuesday overturn ban coal s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  target\n",
       "0       icymi learn mandate rooftop solar power cause ...       0\n",
       "1       nationalhurricanecenter hype storm convince cl...       0\n",
       "2       hey theresistance altleft antifa waronwomen fe...       0\n",
       "3       de jaren ge het globaal koeling compilation ne...       0\n",
       "4       lovely little skybastard idonotconsent wedonot...       0\n",
       "...                                                   ...     ...\n",
       "157192  tonight feel like canada strange turn learn ha...       1\n",
       "157193  lead cause climate change thing far animal agr...       1\n",
       "157194  curious date global air temperature climate ch...       1\n",
       "157195             sign climatechange climateemergencynow       1\n",
       "157196  federal judge rule tuesday overturn ban coal s...       1\n",
       "\n",
       "[157197 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228c5e15-60f0-4ba4-b32c-0331a5827c83",
   "metadata": {
    "id": "228c5e15-60f0-4ba4-b32c-0331a5827c83"
   },
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33abd244-d0e4-4156-a5ab-ac57c8457a8f",
   "metadata": {
    "id": "33abd244-d0e4-4156-a5ab-ac57c8457a8f"
   },
   "outputs": [],
   "source": [
    "# make stopwords list\n",
    "\n",
    "definitive_hashtags = ['climatechangeisreal', 'actonclimate', 'extinctionrebellion', 'climateemergency', \n",
    "                 'climateactionnow', 'capitalism', 'public_health', 'climateaction', 'humanityextinction',\n",
    "                 'activism', 'noplanetb', 'savetheplanet', 'climateaction','climatechangeisfalse', \n",
    "                 'climatechangenotreal', 'climatechangehoax','globalwarminghoax', 'tcot', 'ccot', 'tlot', \n",
    "                 'pjnet', 'rednationrising', 'votered','libtard', 'libtards', 'maga', 'climatedeniers', \n",
    "                 'climatehoax', 'globalcooling','climatechangescam', 'climatehysteria', 'globalwarmingisahoax', \n",
    "                 'globalwarmingscam', 'globalcooling']\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stopwords_all = stop_words.union(definitive_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff7891-5fc4-4b0d-be77-9110afbd72b7",
   "metadata": {
    "id": "10ff7891-5fc4-4b0d-be77-9110afbd72b7",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Baseline Model (81.5% Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96db3476-c256-4f53-a158-7b50da34acb6",
   "metadata": {
    "id": "96db3476-c256-4f53-a158-7b50da34acb6"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8879837-697f-4bf7-a011-cd328dcb9c2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8879837-697f-4bf7-a011-cd328dcb9c2c",
    "outputId": "5412bab4-6cf9-4328-a11f-55de2dbca1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80     14893\n",
      "           1       0.81      0.84      0.83     16547\n",
      "\n",
      "    accuracy                           0.81     31440\n",
      "   macro avg       0.81      0.81      0.81     31440\n",
      "weighted avg       0.81      0.81      0.81     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a count vectorizer\n",
    "vect = CountVectorizer(max_features=1000,stop_words=stopwords_all)\n",
    "\n",
    "# vectorize train and test sets\n",
    "xtrain_count = vect.fit_transform(X_train)\n",
    "xtest_count = vect.transform(X_test)\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "baseline = MultinomialNB()\n",
    "baseline.fit(xtrain_count, y_train)\n",
    "\n",
    "# predict the labels on test set and get evaluation scores\n",
    "baseline_pred = baseline.predict(xtest_count)\n",
    "\n",
    "print(classification_report(y_test, baseline_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "-qP21nZd3jMa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qP21nZd3jMa",
    "outputId": "b5a7add5-7aac-4d8d-c8a5-6961f6144a37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13954,  2593],\n",
       "       [ 3312, 11581]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, baseline_pred, labels = [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "83632a4d-5639-4918-87b4-5aba4464251a",
   "metadata": {
    "id": "83632a4d-5639-4918-87b4-5aba4464251a"
   },
   "outputs": [],
   "source": [
    "filename = 'BaselineNB_81.5%'\n",
    "pickle.dump(baseline, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d7982f-95aa-4991-9a93-d1c9a8a55ed8",
   "metadata": {
    "id": "75d7982f-95aa-4991-9a93-d1c9a8a55ed8",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Logistic Regression + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f6706ad-1b50-4357-8337-3b8fe6587d15",
   "metadata": {
    "id": "0f6706ad-1b50-4357-8337-3b8fe6587d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87     14893\n",
      "           1       0.88      0.90      0.89     16547\n",
      "\n",
      "    accuracy                           0.88     31440\n",
      "   macro avg       0.88      0.88      0.88     31440\n",
      "weighted avg       0.88      0.88      0.88     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF ngram range = 1,3 (Accuracy 88%)\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(1,3), max_df = 0.8, min_df = 3, stop_words=stopwords_all)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)\n",
    "\n",
    "model.fit(X_train_vec, y_train);\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25c5f1dd-7257-464d-b05a-11c309877f58",
   "metadata": {
    "id": "25c5f1dd-7257-464d-b05a-11c309877f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.69      0.76     14893\n",
      "           1       0.76      0.88      0.82     16547\n",
      "\n",
      "    accuracy                           0.79     31440\n",
      "   macro avg       0.80      0.79      0.79     31440\n",
      "weighted avg       0.80      0.79      0.79     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF ngram range = 2,3 (Accuracy 79%)\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(2,3), max_df = 0.8, min_df = 3, stop_words=stopwords_all)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)\n",
    "\n",
    "model.fit(X_train_vec, y_train);\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b51c9-c908-410e-b263-5b88b1926a6e",
   "metadata": {
    "id": "982b51c9-c908-410e-b263-5b88b1926a6e",
    "tags": []
   },
   "source": [
    "## Logistic Regression + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40bd621f-0bc9-4107-beaa-16751b141943",
   "metadata": {
    "id": "40bd621f-0bc9-4107-beaa-16751b141943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80     14893\n",
      "           1       0.84      0.78      0.81     16547\n",
      "\n",
      "    accuracy                           0.80     31440\n",
      "   macro avg       0.80      0.80      0.80     31440\n",
      "weighted avg       0.81      0.80      0.80     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer ngram range = 2,3 (80% Accuracy)\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,3),max_df = 0.8, min_df = 3, stop_words=stopwords_all)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)\n",
    "\n",
    "model.fit(X_train_vec, y_train);\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1cf0ea7c-8ade-41c2-a7ae-f3fbb286a95e",
   "metadata": {
    "id": "1cf0ea7c-8ade-41c2-a7ae-f3fbb286a95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     14893\n",
      "           1       0.89      0.90      0.89     16547\n",
      "\n",
      "    accuracy                           0.89     31440\n",
      "   macro avg       0.89      0.88      0.89     31440\n",
      "weighted avg       0.89      0.89      0.89     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count Vectorizer ngram range = 1,3 (BEST,88% Accuracy)\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,3),max_df = 0.8, min_df = 3, stop_words=stopwords_all)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)\n",
    "\n",
    "model.fit(X_train_vec, y_train);\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9233c9cb-9c80-43c2-b225-f757b52d4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14861,  1686],\n",
       "       [ 1910, 12983]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred,labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "02931249-36db-4f99-bebd-6aa2c7585d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'LR_89.2%'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3053f29-f392-4119-9974-b6093735d055",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Logistic Regression Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87a18cb8-eab4-4d2d-87ad-214798b68161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     14893\n",
      "           1       0.89      0.90      0.89     16547\n",
      "\n",
      "    accuracy                           0.89     31440\n",
      "   macro avg       0.89      0.88      0.89     31440\n",
      "weighted avg       0.89      0.89      0.89     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GridSearch for best parameters\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,3),max_df = 0.8, min_df = 3, stop_words=stopwords_all)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)\n",
    "\n",
    "params = {'penalty': ['none', 'l2'], 'solver': ['liblinear'], 'C': [0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000]}\n",
    "\n",
    "grid = GridSearchCV(LogisticRegression(), params, cv=3, scoring='f1')\n",
    "grid.fit(X_train_vec, y_train)\n",
    "y_true, y_pred = y_test, grid.predict(X_test_vec)\n",
    "\n",
    "print('Best Parameters are:', grid.best_params_)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990ef2b4-7ebc-4917-b4d8-63963480c9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     14893\n",
      "           1       0.89      0.90      0.89     16547\n",
      "\n",
      "    accuracy                           0.89     31440\n",
      "   macro avg       0.89      0.88      0.89     31440\n",
      "weighted avg       0.89      0.89      0.89     31440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train model with optimal parameters\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,3),max_df = 0.8, min_df = 3, stop_words=stopwords_all)\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, solver='liblinear', penalty='l2', C=1)\n",
    "\n",
    "X_train_vec = vect.fit_transform(X_train)\n",
    "X_test_vec  = vect.transform(X_test)\n",
    "\n",
    "model.fit(X_train_vec, y_train);\n",
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919c507-64d5-4b8b-b218-eefe141a27ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classifying Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25620131-3ec6-4aaa-8d79-46a8bae2c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load unseen dataset & assign to X\n",
    "\n",
    "usa = pd.read_pickle(\"../data/usa_tweets_demo.pkl\")\n",
    "X = usa['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7b8d0a2-0128-43a3-8125-5cf83678a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize X\n",
    "\n",
    "X_vec_pred = vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba8c9931-bc35-49db-b70f-9e8eb367b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for the new data\n",
    "\n",
    "y_pred = model.predict_proba(X_vec_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7412992e-b337-4667-8dfa-e00743892842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify data based on 0.5 threshold\n",
    "\n",
    "believer_denier_preds = []\n",
    "\n",
    "for i in y_pred:\n",
    "    if i[1] < 0.5:\n",
    "        believer_denier_preds.append(0)\n",
    "    else:\n",
    "        believer_denier_preds.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e90fe179-f084-4079-9761-c8f0bc207103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    84965\n",
       "0    65833\n",
       "Name: believer_denier, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add classifications to the dataset\n",
    "\n",
    "usa['believer_denier'] = believer_denier_preds\n",
    "usa['believer_denier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6154e83-f2ca-4c0c-b02a-f08f425cc573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    90224\n",
       "0    60574\n",
       "Name: believer_denier, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add classifications to the dataset\n",
    "\n",
    "usa['believer_denier'] = believer_denier_preds\n",
    "usa['believer_denier'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d04e50d7-34bc-4d69-9543-0bf5566b3b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>believer_denier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ll juice left carrot tonight fresh juice morni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climate fact course warm year concern learn cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>planet great winner world move ahead actonclim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teen activist meet staff ve lose faith humanit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescue refugee land sea fleeing conflict need ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150793</th>\n",
       "      <td>savage energy partner record break fiscal quar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150794</th>\n",
       "      <td>hard tell snakeoil chemtrail globalwarmingisah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150795</th>\n",
       "      <td>standard winter hurricane warn part florida yi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150796</th>\n",
       "      <td>happy new yeaя fan globalwarmingisahoax hoax f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150797</th>\n",
       "      <td>september buffalo globalwarmingisahoax</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  believer_denier\n",
       "0       ll juice left carrot tonight fresh juice morni...                1\n",
       "1       climate fact course warm year concern learn cl...                1\n",
       "2       planet great winner world move ahead actonclim...                1\n",
       "3       teen activist meet staff ve lose faith humanit...                1\n",
       "4       rescue refugee land sea fleeing conflict need ...                1\n",
       "...                                                   ...              ...\n",
       "150793  savage energy partner record break fiscal quar...                1\n",
       "150794  hard tell snakeoil chemtrail globalwarmingisah...                0\n",
       "150795  standard winter hurricane warn part florida yi...                1\n",
       "150796  happy new yeaя fan globalwarmingisahoax hoax f...                0\n",
       "150797             september buffalo globalwarmingisahoax                0\n",
       "\n",
       "[150798 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa[['text','believer_denier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e29128a-43f2-4c66-88ce-9990d53bf424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check classifications\n",
    "\n",
    "believers = usa.loc[usa['believer_denier'] == 1]\n",
    "believers = believers.reset_index(drop=True)\n",
    "\n",
    "deniers = usa.loc[usa['believer_denier'] == 0]\n",
    "deniers = deniers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e10447f-999a-4947-9cd0-502315934ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suggest read thread climatechangeisreal ignore'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "believers['text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "745760df-5473-4997-ad80-9618cab56954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prevent bad consequence climate change ahead mean action climatechange actonclimate peoplesclimate rochesterny roc'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "believers['text'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d416a681-3733-4701-bd55-0163dcf610a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'globalwarminghoax believer repent link video climatebarbie head south'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deniers['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2ebdce3-af5f-4b6a-9264-6d81f085311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conservative say environmentalist want clean air water global warming hoax story maga'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deniers['text'][140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca5c3d23-2de5-4fad-9d50-cf1d6ae2e33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save classified dataset\n",
    "\n",
    "usa.to_pickle(\"../data/usa_classified_tweets.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37656257-76ad-4277-9e43-dce99cd76afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing + LR.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
